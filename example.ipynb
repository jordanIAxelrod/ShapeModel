{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb_7CFacpX8S",
        "outputId": "f93ad1b4-67bf-4a3d-f4e9-0c6d56900d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/jordanIAxelrod/ShapeModel\n",
            "  Cloning https://github.com/jordanIAxelrod/ShapeModel to /tmp/pip-req-build-y68yu7_n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jordanIAxelrod/ShapeModel /tmp/pip-req-build-y68yu7_n\n",
            "  Resolved https://github.com/jordanIAxelrod/ShapeModel to commit 2ecb240a96d1453df187c07ba35853eb47970c63\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ShapeModelIMCP\n",
            "  Building wheel for ShapeModelIMCP (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ShapeModelIMCP: filename=ShapeModelIMCP-0.0.1-py3-none-any.whl size=14497 sha256=2184cf3e68c6cfc4d867c29d944a7336ace53f23cace652c76ad185c99f626d0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yktahfp6/wheels/75/e8/43/4ed6aba2f2784dfa18ed6ecb86274dd0cb22e9bad4498a5c08\n",
            "Successfully built ShapeModelIMCP\n",
            "Installing collected packages: ShapeModelIMCP\n",
            "Successfully installed ShapeModelIMCP-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/jordanIAxelrod/ShapeModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shapeModel as ShapeModel\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import skimage.measure"
      ],
      "metadata": {
        "id": "eyYt35bnpsXp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data consists of the masks of several heart valves. This function extracts the boundary of these masks."
      ],
      "metadata": {
        "id": "nU4zZvrOrYHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outline(shape):\n",
        "    point_list = []\n",
        "    shape = skimage.measure.block_reduce(shape, (4,4,4))\n",
        "    for i in range(shape.shape[0]):\n",
        "        for j in range(shape.shape[1]):\n",
        "            for k in range(shape.shape[2]):\n",
        "                if np.any(shape[i - 1: i + 2, j - 1: j + 2, k - 1: k + 2] == 0) and shape[i, j, k] > 0:\n",
        "                    point_list.append([i, j, k])\n",
        "    return np.array(point_list)"
      ],
      "metadata": {
        "id": "MvQsh57wrV7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reads the data from the file system. Get the outline\n",
        "\n",
        "def read_data(folder, leave_out=1):\n",
        "    dataframe = []\n",
        "    cwd = os.getcwd()\n",
        "    os.chdir(folder)\n",
        "    curr_dir = os.listdir()\n",
        "    curr_dir = curr_dir[:leave_out] + curr_dir[leave_out + 1:]\n",
        "\n",
        "    for direct in curr_dir:\n",
        "        os.chdir(direct)\n",
        "        file = os.listdir()[0]\n",
        "\n",
        "        shape_cloud = nib.load(file).get_fdata()\n",
        "        os.chdir('..')\n",
        "        shape_cloud = get_outline(shape_cloud)\n",
        "\n",
        "        dataframe.append(shape_cloud)\n",
        "    min_len = min(dataframe, key=lambda x: x.shape[0]).shape[0]\n",
        "    for i, data in enumerate(dataframe):\n",
        "        choice = np.random.choice(data.shape[0], size=(min_len,), replace=False)\n",
        "        dataframe[i] = torch.Tensor(data[choice]).unsqueeze(0)\n",
        "\n",
        "    os.chdir(cwd)\n",
        "    return torch.cat(dataframe, dim=0)"
      ],
      "metadata": {
        "id": "qvyhkwOOrlVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and fit it. Save if told to\n",
        "def create_ICMP_Model(data, verbose=True, save=False):\n",
        "    model = ShapeModel.ShapeModel()\n",
        "    model(data, verbose=verbose)\n",
        "    if save:\n",
        "        model.save()\n",
        "    return model"
      ],
      "metadata": {
        "id": "NTahRS8usS-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We now run the model twenty times. one for each piece of data\n",
        "# We test the generality of the model by predicting the left out shape on each \n",
        "# model.\n",
        "\n",
        "# Expect this to take a few minutes\n",
        "\n",
        "PATH = r\"C:\\Users\\jda_s\\Box\\bone_project\\heart_dataset\\masks\"\n",
        "generality = {}\n",
        "for i in range(20):\n",
        "    ssm = create_ICMP_Model(read_data(PATH), i==0)\n",
        "    # ssm = IO.load('hi', r\"C:\\Users\\jda_s\\OneDrive\\Documents\\Research\\ShapeModel\\model\\20230209-121010 ICMP.pickle\")\n",
        "    ssm.get_explained_variance()\n",
        "    print(ssm.eig_vecs)\n",
        "    print(ssm.mean_shape, ssm.mean_shape.shape)\n",
        "    cwd = os.getcwd()\n",
        "    print(cwd)\n",
        "    os.chdir(PATH)\n",
        "    curr_dir = os.listdir()[i]\n",
        "    os.chdir(curr_dir)\n",
        "    shape = os.listdir()[0]\n",
        "    new_shape = nib.load(shape).get_fdata()\n",
        "    new_shape = get_outline(new_shape)\n",
        "    choice = np.random.choice(new_shape.shape[0], size=(927,), replace=False)\n",
        "    new_shape = torch.Tensor(new_shape[choice]).unsqueeze(0)\n",
        "    reg_shape = ssm.register_new_shapes(torch.Tensor(new_shape))\n",
        "    generality[i] = []\n",
        "    for j in range(1, ssm.eig_vals.shape[0]):\n",
        "\n",
        "        new_shape1 = ssm.create_shape_approx(reg_shape, j + 1)\n",
        "        dist = torch.sqrt(torch.sum(torch.square(reg_shape - new_shape1)) / (927 * 3))\n",
        "        generality[i].append(dist)\n",
        "    ax = plt.axes(projection='3d')\n",
        "    plt.title('Reconstructions')\n",
        "    ax.scatter(new_shape1[0, :, 0], new_shape1[0, :, 1], new_shape1[0, :, 2])\n",
        "    ax.scatter(reg_shape[0, :, 0], reg_shape[0, :, 1], reg_shape[0, :, 2])\n",
        "    os.chdir(cwd)\n",
        "    print(cwd)\n",
        "    plt.savefig('../img/Reconstruction.png')\n",
        "    plt.show()\n",
        "averages = []\n",
        "for i in range(len(generality[0])):\n",
        "    average = sum([generality[k][i] for k in generality.keys()]) / len(generality)\n",
        "    averages.append(average)\n",
        "plt.title(\"Generality\")\n",
        "plt.xlabel(\"PC Number\")\n",
        "plt.plot(list(range(len(averages))), averages)\n",
        "plt.savefig('../img/Generality.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RQC9SrrrsfzL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}